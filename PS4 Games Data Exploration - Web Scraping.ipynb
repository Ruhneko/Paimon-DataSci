{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS4 GAMES DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be analyzing PS4 game data collected from three different sites, namely ps-timetracker.com, gamepressure.com, and VGchartz.com.\n",
    "\n",
    "**Part 1**: `Data Collection`\n",
    "\n",
    "**Part 2**: `Data Preprocessing`\n",
    "\n",
    "**Part 3**: `Data Analysis`\n",
    "\n",
    "This particular notebook contains the **Part 1** which is data collection part, where we perform web scraping on three different websites to obtain the necessary data, and then store the data on corresponding json files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Data Collection\n",
    "<font color='red'>Valid as of March 2021. Files used for this analysis can be found in the Github repository. </font>\n",
    "\n",
    "This part contians the whole data collection. Due to lack of available datasets on PS4 games, we opted to perform web scraping on three different websites to obtain the necessary data needed for analysis. The following websites that were scraped were PS-TimeTracker, GamePressure, and VGChartz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`request` - used to request a web page\n",
    "\n",
    "`AsyncHTMLSession` - used to request dynamic pages that use java script when loadin\n",
    "\n",
    "`pandas` -  an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "`BeautifulSoup` - a Python library for pulling data out of HTML and XML files.\n",
    "\n",
    "`json` - a lightweight data-interchange format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_html import AsyncHTMLSession\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Web Scraping ps-timetracker.com\n",
    "\n",
    "PS-Timetracker is website that details the top 100 games in a monthly categorical manner based primarly on the total number of hours played, additionally, the dataset also includes the total playerbase, as well as the span of an average session. The website includes both singleplayer-genre games and multiplayer-oriented games, and is regularly updated per month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to request the page and load it onto BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://ps-timetracker.com/statistic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by searching for the required data. We will use January 2021 as the month of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(URL + \"2021-01\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ps-timetracker data is located on a table with the class \"table table-striped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_timetables=soup.find(\"table\", {\"class\": \"table table-striped\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find all the rows and store them into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_timetables=ps4_timetables.find_all('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then select a random row and view the contents so that we can extract them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_row=ps4_timetables[3].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(info_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each even index of the table contains the \\n symbol. The data we are looking for are located on odd indexes.\n",
    "\n",
    "Index \n",
    "\n",
    "1 = Rank, 3 = Chart Movement, 5 =  Game Title, 7 = Hours Played, 9 = Number of Players, 11 = Total Sesssions for the month, and 13 = Average time spent per Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract items of interest\n",
    "Rank=info_row[1].text.strip()\n",
    "Chart_movement=info_row[3].text.strip()\n",
    "Title=info_row[5].text.strip()\n",
    "Hours_Played=info_row[7].text.strip()\n",
    "Players=info_row[9].text.strip()\n",
    "Sessions=info_row[11].text.strip()\n",
    "Avg_Session=info_row[13].text.strip()\n",
    "\n",
    "print(Rank + \" \" + Title + \" \" + \" \" + Hours_Played + \" \" + Players + \" \" + Sessions + \" \" + Avg_Session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create a loop to view each row. The headers are stored on index 0 of the table so we will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_start = 1\n",
    "for i in range(info_start, len(ps4_timetables)-1):\n",
    "    # Extract items of interest\n",
    "    info_row = ps4_timetables[i].contents\n",
    "    Rank=info_row[1].text.strip()\n",
    "    Chart_movement=info_row[3].text.strip()\n",
    "    Title=info_row[5].text.strip()\n",
    "    Hours_Played=info_row[7].text.strip()\n",
    "    Players=info_row[9].text.strip()\n",
    "    Sessions=info_row[11].text.strip()\n",
    "    Avg_Session=info_row[13].text.strip()\n",
    "    print(Rank + \" \" + Title + \" \" + \" \" + Hours_Played + \" \" + Players + \" \" + Sessions + \" \" + Avg_Session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Code 1.1\n",
    "\n",
    "We can see the the Top 100 were able to be  viewed. We will now create the final code which is a double loop. The first loop is for going through each month's page, the format is **\"https:// ps-timetracker.com /statistic/YEAR-MONTH\"**. The second loop is the same as the on above which collects each row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_times_json = []\n",
    "info_start = 1\n",
    "Year = \"2021\"\n",
    "Months = [\"01\",\"02\",\"03\"]\n",
    "\n",
    "for i in range(0, len(Months)):\n",
    "    page=requests.get(URL + Year + \"-\" + Months[i])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ps4_timetables=soup.find(\"table\", {\"class\": \"table table-striped\"})\n",
    "    ps4_timetables=ps4_timetables.find_all('tr')\n",
    "    \n",
    "    for j in range(info_start, len(ps4_timetables)-1):\n",
    "        # Extract items of interest\n",
    "        info_row = ps4_timetables[j].contents\n",
    "        Rank=info_row[1].text.strip()\n",
    "        Chart_Movement=info_row[3].text.strip()\n",
    "        Title=info_row[5].text.strip()\n",
    "        Hours_Played=info_row[7].text.strip()\n",
    "        Players=info_row[9].text.strip()\n",
    "        Sessions=info_row[11].text.strip()\n",
    "        Avg_Session=info_row[13].text.strip()\n",
    "\n",
    "        ps4_times_json.append({\n",
    "            \"Year\": Year,\n",
    "            \"Month\": Months[i],\n",
    "            \"Rank\": Rank,\n",
    "            \"Chart_Movement\": Chart_Movement,\n",
    "            \"Title\": Title,\n",
    "            \"Hours_Played\": Hours_Played,\n",
    "            \"Players\": Players,\n",
    "            \"Sessions\": Sessions,\n",
    "            \"Avg_Session\": Avg_Session\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the collected data to a JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ps4-times.json', 'w') as json_file:\n",
    "    json.dump(ps4_times_json, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the data using a pandas dataframe for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_times_df = pd.json_normalize(ps4_times_json)\n",
    "ps4_times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Web Scraping gamepressure.com\n",
    "\n",
    "Gamepressure is a gaming news and media platform offering guides and walkthroughs on various consoles and gaming platforms. The games on the PS4 platform were scraped from this website. Aside from the title of the game, tags that define the game, its developer, publisher, mode, release date, game description, and ratings were collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 LINK COLLECTION\n",
    "\n",
    "The first step is to request the page and load it onto BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://www.gamepressure.com/games/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game data are stored on diffent pages, we will first go to the ps4 game list page to collect all the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(URL + \"ps4\" + \"/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The links are stored in a div with class \"lista lista-gry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_game_links=soup.find(\"div\", {\"class\": \"lista lista-gry\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will extract each link, which is stored in an anchor with class pic-c\", and place them in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_game_links=ps4_game_links.find_all(\"a\", {\"class\": \"pic-c\"},href=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A for loop to verify if all the links were collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (0, len(ps4_game_links)):\n",
    "    print(ps4_game_links[i]['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Code 1.2.1 Link Collection\n",
    "\n",
    "The final code to collect all links is a double for loop. The outer loop is used to iterate through each page and the inner loop is used to store all the links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_page = 1;\n",
    "end_page = 21\n",
    "ps4_links= []\n",
    "\n",
    "for i in range (start_page, end_page):\n",
    "    page=requests.get(URL + \"ps4\" + \"/-\" + str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ps4_game_links=soup.find(\"div\", {\"class\": \"lista lista-gry\"}) \n",
    "    ps4_game_links=ps4_game_links.find_all(\"a\", {\"class\": \"pic-c\"},href=True) \n",
    "    \n",
    "    for j in range (0, len(ps4_game_links)):\n",
    "        ps4_links.append(ps4_game_links[j]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps4_links[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 GAME DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now select the first link to look for the game data. We will use an AsyncHTMLSession because the ratings portion requires javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://www.gamepressure.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of time it too for pages to render wasn't tracked, so the timeout was set to 0. However, this code may be modified to select a specific timeout to avoid a page connection failure which would freeze the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "session = AsyncHTMLSession()\n",
    "r = await session.get(URL + ps4_links[0])\n",
    "await r.html.arender(timeout=0) \n",
    "print(r.html.raw_html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.html.raw_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game data is stored in a section with class \"article left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_info=soup.find(\"section\", {\"class\": \"article-left\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game title is store  on a span with id \"game-title-cnt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_title = game_info.find(\"span\", {\"id\": \"game-title-cnt\"})\n",
    "print(game_title.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags are stored in anchors within a paragraph with class \"tagi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = []\n",
    "tags = game_info.find(\"p\", {\"class\": \"tagi\"})\n",
    "tags = tags.find_all(\"a\")\n",
    "for i in range(0, len(tags)):\n",
    "    tags_list.append(tags[i].text.strip())\n",
    "\n",
    "tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game developer name is stored in a div with id \"game-developer-cnt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_developer = game_info.find(\"div\", {\"id\": \"game-developer-cnt\"})\n",
    "print(\"developer: \" + game_developer.text.strip().replace(\"developer: \", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game publisher name is stored in a div with id \"game-publisher-cnt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_publisher = game_info.find(\"div\", {\"id\": \"game-publisher-cnt\"})\n",
    "print(\"publisher: \" + game_publisher.text.strip().replace(\"publisher: \", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game mode is stored in a div with class \"S016-game-info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_mode = game_info.find(\"div\", {\"class\": \"S016-game-info\"})\n",
    "game_mode = game_mode.find_all(\"p\")\n",
    "print(\"Game mode: \" + game_mode[3].text.strip().replace(\"Game mode: \", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the release date we first enter a div with id \"game-dates-cnt\". We then find the paragraph with class \"p2\". Withing this pargraph there are three spans that contain the day,month,and year these spans have classes \"s1,s2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_date = game_info.find(\"div\", {\"id\": \"game-dates-cnt\"})\n",
    "release_date = release_date.find(\"p\", {\"class\": \"p2\"})\n",
    "release_date_day = release_date.find(\"span\", {\"class\": \"s1\"})\n",
    "release_date_month = release_date.find(\"span\", {\"class\": \"s2\"}) \n",
    "release_date_year = release_date.find(\"span\", {\"class\": \"s3\"})\n",
    "\n",
    "print(\"Release date: \" + release_date_day.text.strip() + \" \" + release_date_month.text.strip() + \" \" + release_date_year.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game description content varies per page. We will just collect all the content and clean it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_description = game_info.find(\"div\", {\"id\": \"game-description-cnt\"})\n",
    "game_description = game_description.text.strip()\n",
    "game_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game rating is stored in spans within a div with id \"game-mis-cnt\". The firt span (index 0) is the current score, the second span (index 1) is the expected score, both number are stored as the first object (index 0) within the spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game_rating = game_info.find(\"div\", {\"id\": \"game-misc-cnt\"})\n",
    "game_rating = game_rating.find_all(\"span\")\n",
    "\n",
    "current = game_rating[0].find_all(\"b\")[0].text.strip()\n",
    "expected = game_rating[1].find_all(\"b\")[0].text.strip()\n",
    "\n",
    "print(\"Current Score: \" + current)\n",
    "print(\"Expected Score: \" + expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will close the asynch session that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Code 1.2.2 Game Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main loop is a single loop which implements all the subcodes above. The loop iterates over all the links and collects the data. It also saves the data into a json file after collection. The collection took 3-4 hours, there is no error checking or time out for the page requests so that may have played a part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_games_json = []\n",
    "URL=\"https://www.gamepressure.com\"\n",
    "\n",
    "for i in range (0, len(ps4_links)):\n",
    "    session = AsyncHTMLSession()\n",
    "    r = await session.get(URL + ps4_links[i])\n",
    "    await r.html.arender(timeout=0) \n",
    "    soup = BeautifulSoup(r.html.raw_html, 'html.parser')\n",
    "    \n",
    "    game_info = soup.find(\"section\", {\"class\": \"article-left\"}) \n",
    "    \n",
    "    if game_info is not None:\n",
    "        game_title = game_info.find(\"span\", {\"id\": \"game-title-cnt\"})\n",
    "        if game_title is not None:\n",
    "            game_title = game_title.text.strip()\n",
    "\n",
    "        tags_list = []\n",
    "        tags = game_info.find(\"p\", {\"class\": \"tagi\"})\n",
    "        tags = tags.find_all(\"a\")\n",
    "        if tags is not None:\n",
    "            for j in range(0, len(tags)):\n",
    "                tags_list.append(tags[j].text.strip())\n",
    "\n",
    "        game_developer = game_info.find(\"div\", {\"id\": \"game-developer-cnt\"})\n",
    "        if game_developer is not None:\n",
    "            game_developer = game_developer.text.strip().replace(\"developer: \", \"\")\n",
    " \n",
    "        game_publisher = game_info.find(\"div\", {\"id\": \"game-publisher-cnt\"})\n",
    "        if game_publisher is not None:\n",
    "            game_publisher = game_publisher.text.strip().replace(\"publisher: \", \"\")\n",
    "\n",
    "        game_mode = game_info.find(\"div\", {\"class\": \"S016-game-info\"})\n",
    "        game_mode = game_mode.find_all(\"p\")\n",
    "        if(len(game_mode) >= 4):\n",
    "            game_mode = game_mode[3].text.strip().replace(\"Game mode: \", \"\")\n",
    "        else:\n",
    "            game_mode = None\n",
    "\n",
    "        release_date = game_info.find(\"div\", {\"id\": \"game-dates-cnt\"})\n",
    "        release_date = release_date.find(\"p\", {\"class\": \"p2\"})\n",
    "        release_date_day = None\n",
    "        release_date_month = None\n",
    "        release_date_year = None\n",
    "        if release_date.find(\"span\", {\"class\": \"s1\"}) is not None:\n",
    "            release_date_day = release_date.find(\"span\", {\"class\": \"s1\"}).text.strip()\n",
    "        if release_date.find(\"span\", {\"class\": \"s2\"}) is not None:\n",
    "            release_date_month = release_date.find(\"span\", {\"class\": \"s2\"}).text.strip()\n",
    "        if release_date.find(\"span\", {\"class\": \"s3\"}) is not None:\n",
    "            release_date_year = release_date.find(\"span\", {\"class\": \"s3\"}).text.strip()\n",
    "\n",
    "        game_description = game_info.find(\"div\", {\"id\": \"game-description-cnt\"})\n",
    "        if game_description is not None:\n",
    "            game_description = game_description.text.strip()\n",
    "        else:\n",
    "            game_description = None\n",
    "\n",
    "\n",
    "        game_rating = game_info.find(\"div\", {\"id\": \"game-misc-cnt\"})\n",
    "        if game_rating is not  None:\n",
    "            game_rating = game_rating.find_all(\"span\")\n",
    "\n",
    "            if game_rating is None:\n",
    "                current = None\n",
    "                expected = None\n",
    "            elif(len(game_rating) == 2):\n",
    "                current = game_rating[0].find_all(\"b\")[0].text.strip()\n",
    "                expected = game_rating[1].find_all(\"b\")[0].text.strip()\n",
    "            elif (len(game_rating) == 1):\n",
    "                current = None\n",
    "                expected = game_rating[0].find_all(\"b\")[0].text.strip()\n",
    "\n",
    "\n",
    "        ps4_games_json.append({\n",
    "                \"Title\":  game_title,\n",
    "                \"Tags\": tags_list,\n",
    "                \"Developer\": game_developer,\n",
    "                \"Publisher\": game_publisher,\n",
    "                \"Mode\": game_mode,\n",
    "                \"Release_Date_Day\": release_date_day,\n",
    "                \"Release_Date_Month\": release_date_month,\n",
    "                \"Release_Date_Year\": release_date_year,\n",
    "                \"Game_Description\": game_description,\n",
    "                \"Expected_Rating\": expected,\n",
    "                \"Current_Rating\": current\n",
    "        })\n",
    "\n",
    "    await session.close()\n",
    "    \n",
    "with open('ps4-games.json', 'w') as json_file:\n",
    "    json.dump(ps4_games_json, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will view the data in a pandas dataframe for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_times_df = pd.json_normalize(ps4_games_json)\n",
    "ps4_times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Web scraping VGchartz\n",
    "\n",
    "VGCharts is game coverage website that categorizes details of certain games into a database. Details include the platform, title, total shipped, sales from NA region, PAL region, Japan region, and other regions, as well as its total sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create an array with keywords for the consoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = [\"XOne\", \"PS4\", \"PC\", \"NS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search for the data using a randomly selected console. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.vgchartz.com/games/games.php?name=&keyword=&console=\" + console[0] + \"&region=All&developer=&publisher=&goty_year=&genre=&boxart=Both&banner=Both&ownership=Both&showmultiplat=No&results=15000&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0&showvgchartzscore=0&shownasales=0&shownasales=1&showdeveloper=0&showcriticscore=0&showpalsales=0&showpalsales=1&showreleasedate=0&showuserscore=0&showjapansales=0&showjapansales=1&showlastupdate=0&showothersales=0&showothersales=1&showshipped=0&showshipped=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGChartz database is slow and is prone to server errors. We will set a timeout of 300 and check for status code 200/Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 0\n",
    "while(status!=200):\n",
    "    try: \n",
    "        page = requests.get(URL, timeout=300)\n",
    "        status = page.status_code\n",
    "    except requests.exceptions.Timeout as err:\n",
    "        status = 200\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a table, there is no ID so we will just get all table rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_table = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 27 table rows contain random elements from the website, the sales data begins at row 28 and ends at rows-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(sales_table) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_table = sales_table[27:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sales_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the rows, we will now select a random item to extract the sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = sales_table[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find all the items in each row and store them in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = item.find_all(\"td\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored from index 0-9, excluding index 1 and 3.\n",
    "\n",
    "Index 0 = game publisher, Index 2 = game title, Index 4 = total number of copies shipped, Index 5 is the total amount of sales in millions, Index 6-9 are specific sales in millions for North America, PAL, Japan, and Others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_publisher = console[0]\n",
    "sales_title = item[2].text.strip()\n",
    "sales_total_shipped = item[4].text.strip()\n",
    "sales_total_sales = item[5].text.strip()\n",
    "sales_NA_sales = item[6].text.strip()\n",
    "sales_PAL_sales = item[7].text.strip()\n",
    "sales_Japan_sales = item[8].text.strip()\n",
    "sales_Other_sales = item[9].text.strip()\n",
    "\n",
    "\n",
    "print(sales_publisher + \" \" + sales_title + \" \" + sales_total_shipped + \" \" + \n",
    "      sales_total_sales + \" \" + sales_NA_sales + \" \" + sales_PAL_sales + \" \" +\n",
    "     sales_Japan_sales + \" \" + sales_Other_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Code 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main code is a double loop, the outer loop queries for 15,000 objects from each console and the inner loop collects the data. After collecting the data, it is stored in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = [\"XOne\", \"PS4\", \"PC\", \"NS\"]\n",
    "ps4_sales_json = []\n",
    "\n",
    "for i in range (0, len(console)):\n",
    "    URL = \"https://www.vgchartz.com/games/games.php?name=&keyword=&console=\" + console[i] + \"&region=All&developer=&publisher=&goty_year=&genre=&boxart=Both&banner=Both&ownership=Both&showmultiplat=No&results=15000&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0&showvgchartzscore=0&shownasales=0&shownasales=1&showdeveloper=0&showcriticscore=0&showpalsales=0&showpalsales=1&showreleasedate=0&showuserscore=0&showjapansales=0&showjapansales=1&showlastupdate=0&showothersales=0&showothersales=1&showshipped=0&showshipped=1\"\n",
    "    status = 0\n",
    "    while(status!=200):\n",
    "        try: \n",
    "            page = requests.get(URL, timeout=300)\n",
    "            status = page.status_code\n",
    "        except requests.exceptions.Timeout as err:\n",
    "            status = 200\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    sales_table = soup.find_all(\"tr\")\n",
    "    size = len(sales_table) - 1\n",
    "    sales_table = sales_table[27:size]\n",
    "    \n",
    "    for j in range (0, len(sales_table)):\n",
    "        item = sales_table[j]\n",
    "        item = item.find_all(\"td\")\n",
    "        sales_publisher = console[i]\n",
    "        sales_title = item[2].text.strip()\n",
    "        sales_total_shipped = item[4].text.strip()\n",
    "        sales_total_sales = item[5].text.strip()\n",
    "        sales_NA_sales = item[6].text.strip()\n",
    "        sales_PAL_sales = item[7].text.strip()\n",
    "        sales_Japan_sales = item[8].text.strip()\n",
    "        sales_Other_sales = item[9].text.strip()\n",
    "\n",
    "        ps4_sales_json.append({\n",
    "            \n",
    "            \"Publisher\": sales_publisher,\n",
    "            \"Title\": sales_title,\n",
    "            \"Total_Shipped\": sales_total_shipped,\n",
    "            \"Total_Sales\": sales_total_sales,\n",
    "            \"NA_Sales\": sales_NA_sales,\n",
    "            \"PAL_Sales\": sales_PAL_sales,\n",
    "            \"Japan_Sales\": sales_Japan_sales,\n",
    "            \"Other_Sales\": sales_Other_sales \n",
    "             \n",
    "        })\n",
    "        \n",
    "with open('ps4-sales.json', 'w') as json_file:\n",
    "    json.dump(ps4_sales_json, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Missing Files\n",
    "As of April 2021 the Game Pressure site has been updated. Below is the updated code together with a list of links that were not included in the previous scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = ['https://www.gamepressure.com/games/brawlhalla/zf45a5#ps4',\n",
    "'https://www.gamepressure.com/games/call-of-duty-black-ops-iiii/zf51ed#ps4',\n",
    "'https://www.gamepressure.com/games/conan-exiles/z04624#ps4',\n",
    "'https://www.gamepressure.com/games/demons-souls-remake/ze5be2', \n",
    "'https://www.gamepressure.com/games/destruction-allstars/z15be5',\n",
    "'https://www.gamepressure.com/games/diablo-iii-reaper-of-souls-ultimate-evil-edition/z1391d#ps4',\n",
    "'https://www.gamepressure.com/games/dying-light-the-following/z543f8#ps4',\n",
    "'https://www.gamepressure.com/games/enter-the-gungeon/z13f5c#ps4',\n",
    "'https://www.gamepressure.com/games/hollow-knight/z14b7d#ps4',\n",
    "'https://www.gamepressure.com/games/hunt-showdown/z03d4e#ps4',\n",
    "'https://www.gamepressure.com/games/madden-nfl-21/z55b86#ps4',\n",
    "'https://www.gamepressure.com/games/maneater/zd53cb#ps4',\n",
    "'https://www.gamepressure.com/games/monster-hunter-world-iceborne/za579e#ps4',\n",
    "'https://www.gamepressure.com/games/nba-2k20/z85847#ps4',\n",
    "'https://www.gamepressure.com/games/persona-5-scramble-the-phantom-strikers/z75783#ps4',\n",
    "'https://www.gamepressure.com/games/smite/z02de5#ps4',\n",
    "'https://www.gamepressure.com/games/tom-clancys-rainbow-six-siege/z23d74#ps4',\n",
    "'https://www.gamepressure.com/games/warface/z4259d#ps4',\n",
    "'https://www.gamepressure.com/games/we-were-here/ze4cbe#ps4',\n",
    "'https://www.gamepressure.com/games/world-of-tanks-mercenaries/z229e2#ps4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps4_missing_games_json = []\n",
    "\n",
    "for i in range (0, len(missing)):\n",
    "    session = AsyncHTMLSession()\n",
    "    r = await session.get(missing[i])\n",
    "    await r.html.arender(timeout=0) \n",
    "    soup = BeautifulSoup(r.html.raw_html, 'html.parser')\n",
    "    \n",
    "    game_info = soup.find(\"section\", {\"class\": \"article-left\"}) \n",
    "    \n",
    "    if game_info is not None:\n",
    "        game_title = game_info.find(\"span\", {\"id\": \"game-title-cnt\"})\n",
    "        if game_title is not None:\n",
    "            game_title = game_title.text.strip()\n",
    "\n",
    "        tags_list = []\n",
    "        tags = game_info.find(\"p\", {\"class\": \"tagi\"})\n",
    "        tags = tags.find_all(\"a\")\n",
    "        if tags is not None:\n",
    "            for j in range(0, len(tags)):\n",
    "                tags_list.append(tags[j].text.strip())\n",
    "\n",
    "        game_developer = game_info.find(\"span\", {\"id\": \"game-developer-cnt\"})\n",
    "        if game_developer is not None:\n",
    "            game_developer = game_developer.text.strip().replace(\"developer: \", \"\")\n",
    " \n",
    "        game_publisher = game_info.find(\"span\", {\"id\": \"game-publisher-cnt\"})\n",
    "        if game_publisher is not None:\n",
    "            game_publisher = game_publisher.text.strip().replace(\"publisher: \", \"\")\n",
    "\n",
    "        game_mode = game_info.find(\"div\", {\"id\": \"game-misc-cnt\"})\n",
    "        game_mode = game_mode.find_all(\"p\")\n",
    "        game_mode = game_mode[0].find(\"b\")\n",
    "        game_mode =game_mode.text.strip()\n",
    "\n",
    "        release_date = game_info.find(\"div\", {\"id\": \"game-dates-cnt\"})\n",
    "        release_date = release_date.find(\"p\", {\"class\": \"p2\"})\n",
    "        release_date_day = None\n",
    "        release_date_month = None\n",
    "        release_date_year = None\n",
    "        if release_date.find(\"span\", {\"class\": \"s1\"}) is not None:\n",
    "            release_date_day = release_date.find(\"span\", {\"class\": \"s1\"}).text.strip()\n",
    "        if release_date.find(\"span\", {\"class\": \"s2\"}) is not None:\n",
    "            release_date_month = release_date.find(\"span\", {\"class\": \"s2\"}).text.strip()\n",
    "        if release_date.find(\"span\", {\"class\": \"s3\"}) is not None:\n",
    "            release_date_year = release_date.find(\"span\", {\"class\": \"s3\"}).text.strip()\n",
    "\n",
    "        game_description = game_info.find(\"div\", {\"id\": \"game-description-cnt\"})\n",
    "        if game_description is not None:\n",
    "            game_description = game_description.text.strip()\n",
    "        else:\n",
    "            game_description = None\n",
    "\n",
    "\n",
    "        game_rating = game_info.find(\"div\", {\"id\": \"game-misc-cnt\"})\n",
    "       \n",
    "        if game_rating is not  None:\n",
    "            game_rating = game_rating.find_all(\"p\")\n",
    "\n",
    "            if game_rating is None:\n",
    "                current = None\n",
    "                expected = None\n",
    "            elif(len(game_rating) == 3):\n",
    "                current = game_rating[1].find_all(\"b\")[0].text.strip()\n",
    "                expected = game_rating[2].find_all(\"b\")[0].text.strip()\n",
    "            elif (len(game_rating) == 2):\n",
    "                current = None\n",
    "                expected = game_rating[1].find_all(\"b\")[0].text.strip()\n",
    "\n",
    "\n",
    "        ps4_missing_games_json.append({\n",
    "                \"Title\":  game_title,\n",
    "                \"Tags\": tags_list,\n",
    "                \"Developer\": game_developer,\n",
    "                \"Publisher\": game_publisher,\n",
    "                \"Mode\": game_mode,\n",
    "                \"Release_Date_Day\": release_date_day,\n",
    "                \"Release_Date_Month\": release_date_month,\n",
    "                \"Release_Date_Year\": release_date_year,\n",
    "                \"Game_Description\": game_description,\n",
    "                \"Expected_Rating\": expected,\n",
    "                \"Current_Rating\": current\n",
    "        })\n",
    "\n",
    "    await session.close()\n",
    "    \n",
    "with open('ps4-games-missing.json', 'w') as json_file:\n",
    "    json.dump(ps4_missing_games_json, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That concludes the data collection part.\n",
    "\n",
    "The data is now stored into corresponding json files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
